{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "16c0c4df-1e18-463f-ad97-e6feb079c7ba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%pip install beautifulsoup4\n",
    "%pip install pandas\n",
    "%pip install webdriver-manager\n",
    "%pip install selenium\n",
    "%pip install multiprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b84acdbc-cc6a-4c39-8742-7705a8003384",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from bs4 import BeautifulSoup as BS\n",
    "from multiprocessing import Process\n",
    "import pandas as pd\n",
    "from urllib.parse import urlparse, urlsplit\n",
    "import time\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dd4b7e94-6f9c-460e-9d5d-c3a22f7e2929",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Ski Homes\n",
    "\n",
    "ski_homes = [\n",
    "    {\n",
    "        'loc': 'breckinridge',\n",
    "        'url': 'https://www.airbnb.com/s/Breckenridge--CO/homes?adults=1&place_id=ChIJwecmbD32aocReqKAZn-PjWI&refinement_paths%5B%5D=%2Fhomes'\n",
    "    }, \n",
    "    {\n",
    "        'loc': 'parkcity',\n",
    "        'url': 'https://www.airbnb.com/s/Park-City--UT/homes?adults=1&place_id=ChIJ_QNjLGMPUocRlFc3Jd_Ecdg&refinement_paths%5B%5D=%2Fhomes'\n",
    "    }, \n",
    "    {\n",
    "        'loc': 'jacksonhole',\n",
    "        'url': 'https://www.airbnb.com/s/Jackson-Hole--WY/homes?adults=1&place_id=ChIJS3_P_FgaU1MRXIM6scsBHD0&refinement_paths%5B%5D=%2Fhomes'\n",
    "    }, \n",
    "    {\n",
    "        'loc': 'vail',\n",
    "        'url': 'https://www.airbnb.com/s/Vail--CO/homes?adults=1&place_id=ChIJB89dUQVwaocRxKOafh_AzMk&refinement_paths%5B%5D=%2Fhomes'\n",
    "    },\n",
    "    {\n",
    "        'loc': 'steamboat',\n",
    "        'url': 'https://www.airbnb.com/s/Steamboat-Springs--CO/homes?adults=1&place_id=ChIJYUZWCYF7QocRfc9uSNGjqBs&refinement_paths%5B%5D=%2Fhomes'\n",
    "    },\n",
    "    {\n",
    "        'loc': 'bigsky',\n",
    "        'url': 'https://www.airbnb.com/s/Big-Sky--MT/homes?adults=1&place_id=ChIJNSw3_WUOUFMRyiuLqjtx-JU&refinement_paths%5B%5D=%2Fhomes'\n",
    "    },\n",
    "    {\n",
    "        'loc': 'telluride',\n",
    "        'url': 'https://www.airbnb.com/s/Telluride--CO/homes?adults=1&place_id=ChIJc_TmcHvYPocR4eO6cSF37jg&refinement_paths%5B%5D=%2Fhomes'\n",
    "    },\n",
    "    {\n",
    "        'loc': 'aspen',\n",
    "        'url': 'https://www.airbnb.com/s/Aspen--CO/homes?adults=1&place_id=ChIJfTxB93w5QIcRcvYseNxCK8E&refinement_paths%5B%5D=%2Fhomes'\n",
    "    },\n",
    "    {\n",
    "        'loc': 'tahoe',\n",
    "        'url': 'https://www.airbnb.com/s/Lake-Tahoe/homes?adults=1&place_id=ChIJUREfuaF4mYARILWv7q8fP4w&refinement_paths%5B%5D=%2Fhomes'\n",
    "    },\n",
    "    {\n",
    "        'loc': 'tahoe',\n",
    "        'url': 'https://www.airbnb.com/s/Taos--NM/homes?adults=1&place_id=ChIJsfwRf9pkF4cRgrepYYOR6pA&refinement_paths%5B%5D=%2Fhomes'\n",
    "    }\n",
    "]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9bacc865-afde-4bea-8418-bb4a5be124cd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"Scrape HTML from page\"\"\"\n",
    "\n",
    "def scrape_page(page_url):\n",
    "    \n",
    "    answer = requests.get(page_url)\n",
    "    content = answer.content\n",
    "    soup = BS(content, features='html.parser')\n",
    "    \n",
    "    return soup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "50684603-610e-4704-b22d-f23d0ec552db",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\" Children functions that scrape \"\"\"\n",
    "\n",
    "def getListingName(soup):\n",
    "    try: \n",
    "        return soup.find(\"span\", {\"class\": \"_1n81at5\"}).get_text()\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "def getListingRating(soup):\n",
    "    try: \n",
    "        text = soup.find(\"span\", {\"class\": \"_17p6nbba\"}).get_text()\n",
    "        num = text.split(' ')[0]\n",
    "        return float(num)\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "def getNumberReviews(soup):\n",
    "    try:\n",
    "        txt = soup.find(\"span\", {\"class\": \"_s65ijh7\"}).get_text()\n",
    "        num_reviews = []\n",
    "        for el in txt:\n",
    "            if (el == ' '):\n",
    "                break\n",
    "\n",
    "            num_reviews.append(el)\n",
    "\n",
    "        return float(''.join(num_reviews))\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "\n",
    "def isSuperhost(soup):\n",
    "    try:\n",
    "        output = soup.find(\"span\", {\"class\": \"_1mhorg9\"}).get_text() == 'Superhost'\n",
    "    except:\n",
    "        output = False\n",
    "    return output\n",
    "\n",
    "def isNewListing(soup):\n",
    "    try:\n",
    "        output = soup.find(\"span\", {\"class\": \"_1mhorg9\"}).get_text() == 'New'\n",
    "    except:\n",
    "        output = False\n",
    "    return output\n",
    "\n",
    "def getLocationData(soup):\n",
    "    try: \n",
    "        [city, state, country] = soup.find(\"span\", {\"class\": \"_9xiloll\"}).get_text().split(', ')\n",
    "        return [city, state, country]\n",
    "    except:\n",
    "        return [None, None, None]\n",
    "\n",
    "def makeListingPriceFloat(string):\n",
    "        price_chars = []\n",
    "        for char in string:\n",
    "            isBadChar = char == '$' or char == ','\n",
    "            if (not isBadChar):\n",
    "                price_chars.append(char)\n",
    "        \n",
    "        return float(''.join(price_chars))\n",
    "\n",
    "def getPriceOfElement(soup, class_name):\n",
    "    try:\n",
    "        price_txt = soup.find(\"span\", {\"class\": class_name}).get_text()\n",
    "        return makeListingPriceFloat(price_txt)\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "def extractFromElemArray(array, fn):\n",
    "    for elem in array:\n",
    "        fn(elem)\n",
    "        \n",
    "def labelChecker(txt):\n",
    "    string = txt.get_text()\n",
    "    if 'night' in string:\n",
    "        return 'multi_day_deal'\n",
    "\n",
    "    if 'Cleaning' in string:\n",
    "        return 'cleaning_fee'\n",
    "\n",
    "    if 'service' in string:\n",
    "        return 'airbnb_service_fee'\n",
    "    return None\n",
    "\n",
    "def getPricesFromMiniGuide(soup):\n",
    "    output = {\n",
    "        \"multi_day_deal\" : None, \n",
    "        \"cleaning_fee\" : None,\n",
    "        \"airbnb_service_fee\" : None\n",
    "    }\n",
    "    \n",
    "    try: \n",
    "        all_prices = soup.find(\"div\", {\"data-section-id\": \"BOOK_IT_SIDEBAR\"}).findAll(\"span\", {\"class\":\"_1k4xcdh\"})\n",
    "        all_labels = soup.find(\"div\", {\"data-section-id\": \"BOOK_IT_SIDEBAR\"}).findAll(\"div\", {\"class\":\"_m6lwl6\"})\n",
    "        formatted_labels = list(map(labelChecker, all_labels))\n",
    "        \n",
    "        for index, elem in enumerate(all_prices):\n",
    "            if(elem == None):\n",
    "                continue\n",
    "            float_price = makeListingPriceFloat(elem.get_text())\n",
    "            \n",
    "            if(formatted_labels[index] != None):\n",
    "                output[formatted_labels[index]] = float_price\n",
    "        return output\n",
    "    except:\n",
    "        return output\n",
    "\n",
    "def getTopRatingCategories(soup):\n",
    "    top_categories = []\n",
    "    raw_text= soup.findAll(\"div\", {\"class\":\"_y1ba89\"})\n",
    "    for elem in raw_text:\n",
    "        top_categories.append(elem.get_text())\n",
    "    return top_categories\n",
    "    \n",
    "def getOrigPricePerNight(soup):\n",
    "    try: \n",
    "        return getPriceOfElement(soup, \"_1ks8cgb\")\n",
    "    except: \n",
    "        return None\n",
    "\n",
    "def getReducedPricePerNight(soup):\n",
    "    try: \n",
    "        return getPriceOfElement(soup, \"_1y74zjx\")\n",
    "    except: \n",
    "        return None\n",
    "\n",
    "def getNightlyPrice(soup):\n",
    "    try: \n",
    "        return getPriceOfElement(soup, \"_tyxjp1\")\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "        \n",
    "def getNumberFromString(sentence):\n",
    "    items = sentence.split(' ')\n",
    "    \n",
    "    for item in items:\n",
    "        if (item.isnumeric()):\n",
    "            return float(item)\n",
    "        if(len(item) > 3):\n",
    "            return item\n",
    "        \n",
    "    return None\n",
    "            \n",
    "\n",
    "\n",
    "def getSleepingArrangement(soup):\n",
    "    output = {\n",
    "        'listing_size': None,\n",
    "        'num_guests': None,\n",
    "        'num_bedrooms': None,\n",
    "        'num_bathrooms': None\n",
    "    }\n",
    "    try:\n",
    "        all_items = soup.find(\"div\", {\"class\": \"_tqmy57\"}).findAll(\"li\", {\"class\": \"l7n4lsf\"})\n",
    "        sleeping_arrangment = []\n",
    "        for index, elem in enumerate(all_items):\n",
    "            item = elem.get_text()\n",
    "            \n",
    "            if index == 1:\n",
    "                output['listing_size'] = getNumberFromString(item)\n",
    "                continue\n",
    "                \n",
    "            if 'guests' in item:\n",
    "                output['num_guests'] = getNumberFromString(item)\n",
    "                \n",
    "                \n",
    "            if 'bed' in item:\n",
    "                output['num_bedrooms'] = getNumberFromString(item)\n",
    "                \n",
    "            if 'bath' in item:\n",
    "                output['num_bathrooms'] = getNumberFromString(item)\n",
    "\n",
    "        return output\n",
    "    except:\n",
    "        return output\n",
    "\n",
    "def getAmmenities(soup):\n",
    "    try:\n",
    "        elements = soup.findAll(\"div\", {\"class\": \"t1dx2edb\"})\n",
    "        output = []\n",
    "        for elem in elements:\n",
    "            output.append(elem.get_text())\n",
    "        return output\n",
    "    except:\n",
    "        return []\n",
    "\n",
    "def hasHotTub(array):\n",
    "    try:\n",
    "        output = False \n",
    "        for item in array:\n",
    "            if item.find(\"hot\") and item.find(\"tub\"):\n",
    "                output = True\n",
    "        return output\n",
    "    except:\n",
    "        return False\n",
    "\n",
    "def isSkiInSkiOut(array):\n",
    "    try:\n",
    "        output = False \n",
    "        for item in array:\n",
    "            if item.find(\"Ski-in/ski-out\"):\n",
    "                output = True\n",
    "        return output\n",
    "    except:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a86b002e-a751-46e1-b3e7-dfbd8ee56817",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Parent function to scrape all diff items from page \"\"\"\n",
    "def extract_listing(page_url):\n",
    "    \n",
    "    page_soup = scrape_page(page_url)\n",
    "    listings = page_soup.findAll(\"div\", {\"class\": \"_8s3ctt\"})\n",
    "\n",
    "    return listings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9a0bb011-3bc4-401f-b28c-281a300dba07",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\" Builds urls for defined data set \"\"\"\n",
    "\n",
    "def buildGridPageUrls(url, listings_per_page=20, pages_per_location=15):\n",
    "    \"\"\"Builds all search pages for a given location... 15 search pages, 20 items per page for 300 listings\"\"\"\n",
    "    url_list = []\n",
    "    for i in range(pages_per_location):\n",
    "        offset = listings_per_page * i\n",
    "        url_pagination = url + f'&items_offset={offset}'\n",
    "        url_list.append(url_pagination)\n",
    "    return url_list\n",
    "\n",
    "\n",
    "def getAllHomeLinks(soup):\n",
    "    elem_list = soup.findAll(\"div\", {\"class\": \"c4mnd7m\"})\n",
    "    link_list = []\n",
    "    airbnb_base_url = 'https://www.airbnb.com'\n",
    "    for elem in elem_list:\n",
    "        url = airbnb_base_url + elem.find(\"a\", {\"class\":\"l1j9v1wn\"}).get(\"href\")\n",
    "        link_list.append(url)\n",
    "    return link_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a6f2a8b7-db4b-4520-a2c9-4b2e64eb61b3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def findNextPage(soup):\n",
    "    try:\n",
    "        nextpage = \"https://airbnb.com\" + soup.find(\"a\", {\"aria-label\": \"Next\"}).get(\"href\")\n",
    "    except:\n",
    "        nextpage = \"no next page\"\n",
    "    return nextpage\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4e33b9c7-64dd-478b-8eae-48d4d7ae97cc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def setupDriver(): \n",
    "    ChromeDriverManager().install()\n",
    "    options = Options()\n",
    "    options.page_load_strategy = 'normal'\n",
    "    options.add_argument('--headless')\n",
    "    options.add_argument('--no-sandbox')\n",
    "    driver = webdriver.Chrome(options=options)\n",
    "    return driver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "219a153d-c6c4-4c1d-ab64-f2c5e68f4638",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def extractRentalInformation(url, page_wait = 3, click_wait = 3):\n",
    "    driver = setupDriver()\n",
    "    driver.get(url)\n",
    "\n",
    "    time.sleep(page_wait)\n",
    "    \n",
    "    try:\n",
    "        driver.find_elements(By.CLASS_NAME, \"v7aged4\")[0].click()\n",
    "    except:\n",
    "        pass # amenities button not found\n",
    "    \n",
    "    time.sleep(click_wait)\n",
    "\n",
    "    details_page = driver.page_source\n",
    "    driver.quit()\n",
    "\n",
    "    soup = BS(details_page, features='html.parser')\n",
    "\n",
    "    [city, state, country] = getLocationData(soup)\n",
    "    multi_day_deal, cleaning_fee, airbnb_service_fee = getPricesFromMiniGuide(soup).values()\n",
    "    listing_size, num_guests, num_bedrooms, num_bathrooms = getSleepingArrangement(soup).values()\n",
    "    ammenities = getAmmenities(soup)\n",
    "    reducedPricePerNight = getReducedPricePerNight(soup)\n",
    "    origPricePerNight = getOrigPricePerNight(soup)\n",
    "    chargePrice = getNightlyPrice(soup) or reducedPricePerNight or origPricePerNight\n",
    "    \n",
    "    dictionary = {\n",
    "        \"title\": [getListingName(soup)], \n",
    "        \"rating\" : [getListingRating(soup)], \n",
    "        \"nightlyRate\" : [chargePrice],\n",
    "        \"city\" : [city],\n",
    "        \"state\" : [state],\n",
    "        \"country\" : [country],\n",
    "        \"numberOfReviews\": [getNumberReviews(soup)], \n",
    "        \"originalPricePerNight\": [origPricePerNight],\n",
    "        \"reducedPricePerNight\" : [reducedPricePerNight],\n",
    "        \"listing_size\": [listing_size],\n",
    "        \"num_guests\" : [num_guests],\n",
    "        \"num_bedrooms\": [num_bedrooms],\n",
    "        \"num_bathrooms\": [num_bathrooms],\n",
    "        \"multiDayDeal\": [multi_day_deal],\n",
    "        \"cleaningFee\" : [cleaning_fee],\n",
    "        \"airbnbServiceFee\" : [airbnb_service_fee],\n",
    "        \"newListing\": [isNewListing(soup)], \n",
    "        \"skiInSkiOut\": [isSkiInSkiOut(ammenities)], \n",
    "        \"superHost\" : [isSuperhost(soup)], \n",
    "        \"hotTub\": [hasHotTub(ammenities)],\n",
    "        \"url\" : [url]\n",
    "    }\n",
    "    \n",
    "    return pd.DataFrame(dictionary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "82ac1dee-2278-48ef-8ad7-2b4a57e3beb5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def createAllListings(cityList):\n",
    "    # for city in cityList:\n",
    "    \n",
    "    listings = []\n",
    "    for city in cityList:\n",
    "        allSearchUrls = buildGridPageUrls(city[\"url\"])\n",
    "        # for searchPage in allSearchUrls:\n",
    "        for searchPage in allSearchUrls:\n",
    "            listings.extend(getLinksForAllListingsInSearch(searchPage))\n",
    "        \n",
    "    return listings\n",
    "    \n",
    "def getLinksForAllListingsInSearch(url):\n",
    "    driver = setupDriver()\n",
    "    driver.get(url)\n",
    "    time.sleep(2)\n",
    "    details_page = driver.page_source\n",
    "\n",
    "    driver.quit()\n",
    "\n",
    "    soup = BS(details_page, features='html.parser')\n",
    "    return getAllHomeLinks(soup)\n",
    "\n",
    "def createDataFrame(listings):\n",
    "    dataFrames = []\n",
    "    for listing in listings:\n",
    "        pageDF = extractRentalInformation(listing)\n",
    "        dataFrames.append(pageDF)\n",
    "        \n",
    "    df = pd.concat(dataFrames, ignore_index = True)\n",
    "    df.reset_index()\n",
    "    return df\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7f6bd9b5-e190-4ada-a5b2-c7f75792b9bb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "listings = createAllListings(ski_homes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "caf64df2-6aa8-4f30-b04f-3557da3c7942",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "listings_df = pd.DataFrame(listings)\n",
    "listings_df = listings_df.rename(columns = {0: 'cityUrl'})\n",
    "listings_df.to_csv('listings.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3c645a8b-df13-4175-97d2-06d419bc7c4e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "def extractAndCreateCsv(cityList):\n",
    "    #create all listings\n",
    "    listings = createAllListings(cityList)\n",
    "    \n",
    "    test = listings[:3]\n",
    "    \n",
    "    df = createDataFrame(test)\n",
    "    # # return df.to_csv('intermediate_results_par.csv', mode='a', header=True, index=False)\n",
    "    return df.to_csv('scrapedData.csv', mode='a', header=True, index=False)\n",
    "\n",
    "\n",
    "extractAndCreateCsv(ski_homes)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
